{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo code\n",
    "1. get into directory and list all the folders in the directory \n",
    "2. get in each folder and list all the files \n",
    "3. open each file from row 5\n",
    "4. merge into data frame \n",
    "5. merge all the files into a single dataframe and export into a new csv\n",
    "6. perform logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import logging as lg\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.basicConfig(filename=\"logs.txt\",level=lg.INFO,format=\"%(asctime)s:%(levelname)s: %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class mergeRawdata:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def list_dir(self):\n",
    "        try:\n",
    "            files = os.listdir(self.path)\n",
    "            lg.info(\"list_dir() called\")\n",
    "            lg.info(files)\n",
    "        except Exception as e:\n",
    "            lg.error(e)\n",
    "\n",
    "    def merge_csv_opr(self):\n",
    "        lg.info(\"merge_csv_opr() called\")\n",
    "        try:\n",
    "            files = os.listdir(self.path)\n",
    "            cwd_ = os.getcwd()\n",
    "            name = \"merged_folder\"\n",
    "            p = os.path.join(cwd_, name)\n",
    "            os.makedirs(p, exist_ok=True)\n",
    "            for file in files:\n",
    "                if file.endswith('.pdf'):\n",
    "                    lg.info(\" .PDF file detected, skipping the file\")\n",
    "                    continue\n",
    "                else:\n",
    "                    list_of_csv_in_folder = []\n",
    "                    folder = os.path.join(self.path, file)\n",
    "                    csv_files = os.listdir(folder)\n",
    "                    try:\n",
    "                        for csv in csv_files:\n",
    "                            csv_path = os.path.join(folder, csv)\n",
    "                            try:\n",
    "                                df = pd.read_csv(csv_path, skiprows=4)\n",
    "                            except Exception as e:\n",
    "                                lg.error(e)\n",
    "                                lg.info(\"Anomalies deteced in csv file, hence skipping\")\n",
    "                                continue\n",
    "                            list_of_csv_in_folder.append(df)\n",
    "                        merged_df = pd.concat(list_of_csv_in_folder, ignore_index=True)\n",
    "                        os.chdir(p)\n",
    "                        name = f\"{file}.csv\"\n",
    "                        merged_df.to_csv(name)\n",
    "                    except Exception as e:\n",
    "                        lg.error(e)\n",
    "\n",
    "                        continue\n",
    "        except Exception as e:\n",
    "            lg.error(e)\n",
    "        lg.info(\"Operation successful\")\n",
    "        print(\"All Merging Successful and is available in current dir in Merged_folder\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Merging Successful and is available in current dir in Merged_folder\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\Abhishek Mazumdar\\\\Downloads\\\\AReM\"\n",
    "obj = mergeRawdata(path)\n",
    "obj.merge_csv_opr()\n",
    "lg.info(\"Object created with path to folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=Picture1.png width='300'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening each folder and adding a column of categories same as file name and merging all of them into one final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class df_operation:\n",
    "    \n",
    "    def add_category_merge(self):\n",
    "        lg.info(\"add_category_merge function called\")\n",
    "        cwd = os.getcwd()\n",
    "        csv_files = os.listdir(cwd)\n",
    "        csv_list =[]\n",
    "        try:\n",
    "            for csv in csv_files:\n",
    "                sub_path = os.path.join(cwd,csv)\n",
    "                df = pd.read_csv(sub_path)\n",
    "                df[\"category\"] = csv.split(\".\")[0]\n",
    "                lg.info(f\"Category column : {csv} added to csv file {csv}\")\n",
    "                csv_list.append(df)\n",
    "            final_dataframe = pd.concat(csv_list,ignore_index=True)\n",
    "            os.chdir(cwd)\n",
    "            final_dataframe.to_csv(\"final_csv.csv\")\n",
    "            lg.info(\"Final_csv file created by merging all the csv files\")\n",
    "        except Exception as e:\n",
    "            lg.error(e)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = df_operation()\n",
    "o.add_category_merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=Picture2.png width=\"200\">\n",
    "\n",
    "final_csv Created \n",
    "\n",
    "Now Performing EDA operation on the final dataset followed my Logistic regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\INEURON\\\\TASKS_Class\\\\merged_folder\\\\final_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th># Columns: time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>750</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41274</th>\n",
       "      <td>41274</td>\n",
       "      <td>7195</td>\n",
       "      <td>118750</td>\n",
       "      <td>31.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>12.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4.44</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41275</th>\n",
       "      <td>41275</td>\n",
       "      <td>7196</td>\n",
       "      <td>119000</td>\n",
       "      <td>27.33</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>20.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41276</th>\n",
       "      <td>41276</td>\n",
       "      <td>7197</td>\n",
       "      <td>119250</td>\n",
       "      <td>37.80</td>\n",
       "      <td>7.68</td>\n",
       "      <td>14.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41277</th>\n",
       "      <td>41277</td>\n",
       "      <td>7198</td>\n",
       "      <td>119500</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>15.75</td>\n",
       "      <td>5.21</td>\n",
       "      <td>16.50</td>\n",
       "      <td>2.69</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41278</th>\n",
       "      <td>41278</td>\n",
       "      <td>7199</td>\n",
       "      <td>119750</td>\n",
       "      <td>32.67</td>\n",
       "      <td>3.09</td>\n",
       "      <td>18.67</td>\n",
       "      <td>0.47</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41279 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1 # Columns: time  avg_rss12  var_rss12  \\\n",
       "0               0             0               0      39.25       0.43   \n",
       "1               1             1             250      39.25       0.43   \n",
       "2               2             2             500      39.25       0.43   \n",
       "3               3             3             750      39.50       0.50   \n",
       "4               4             4            1000      39.50       0.50   \n",
       "...           ...           ...             ...        ...        ...   \n",
       "41274       41274          7195          118750      31.50       1.66   \n",
       "41275       41275          7196          119000      27.33       1.25   \n",
       "41276       41276          7197          119250      37.80       7.68   \n",
       "41277       41277          7198          119500      33.75       1.30   \n",
       "41278       41278          7199          119750      32.67       3.09   \n",
       "\n",
       "       avg_rss13  var_rss13  avg_rss23  var_rss23  category  \n",
       "0          22.75       0.43      33.75       1.30  bending1  \n",
       "1          23.00       0.00      33.00       0.00  bending1  \n",
       "2          23.25       0.43      33.00       0.00  bending1  \n",
       "3          23.00       0.71      33.00       0.00  bending1  \n",
       "4          24.00       0.00      33.00       0.00  bending1  \n",
       "...          ...        ...        ...        ...       ...  \n",
       "41274      12.50       3.20      14.25       4.44   walking  \n",
       "41275      11.33       0.94      20.00       4.00   walking  \n",
       "41276      14.20       2.48      17.25       0.83   walking  \n",
       "41277      15.75       5.21      16.50       2.69   walking  \n",
       "41278      18.67       0.47      14.00       3.16   walking  \n",
       "\n",
       "[41279 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bending1', 'bending2', 'cycling', 'lying', 'sitting', 'standing',\n",
       "       'walking'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform Logistic regression where two types of classifications are basically performed \n",
    "1. Binary classification \n",
    "2. One VS Rest classification\n",
    "\n",
    "I will be performing one VS rest classification to classify bending1 VS not bending1 (rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\",\"Unnamed: 0.1\",\"# Columns: time\"],axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41274</th>\n",
       "      <td>31.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>12.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4.44</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41275</th>\n",
       "      <td>27.33</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>20.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41276</th>\n",
       "      <td>37.80</td>\n",
       "      <td>7.68</td>\n",
       "      <td>14.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41277</th>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>15.75</td>\n",
       "      <td>5.21</td>\n",
       "      <td>16.50</td>\n",
       "      <td>2.69</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41278</th>\n",
       "      <td>32.67</td>\n",
       "      <td>3.09</td>\n",
       "      <td>18.67</td>\n",
       "      <td>0.47</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41279 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  var_rss23  \\\n",
       "0          39.25       0.43      22.75       0.43      33.75       1.30   \n",
       "1          39.25       0.43      23.00       0.00      33.00       0.00   \n",
       "2          39.25       0.43      23.25       0.43      33.00       0.00   \n",
       "3          39.50       0.50      23.00       0.71      33.00       0.00   \n",
       "4          39.50       0.50      24.00       0.00      33.00       0.00   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "41274      31.50       1.66      12.50       3.20      14.25       4.44   \n",
       "41275      27.33       1.25      11.33       0.94      20.00       4.00   \n",
       "41276      37.80       7.68      14.20       2.48      17.25       0.83   \n",
       "41277      33.75       1.30      15.75       5.21      16.50       2.69   \n",
       "41278      32.67       3.09      18.67       0.47      14.00       3.16   \n",
       "\n",
       "       category  \n",
       "0      bending1  \n",
       "1      bending1  \n",
       "2      bending1  \n",
       "3      bending1  \n",
       "4      bending1  \n",
       "...         ...  \n",
       "41274   walking  \n",
       "41275   walking  \n",
       "41276   walking  \n",
       "41277   walking  \n",
       "41278   walking  \n",
       "\n",
       "[41279 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "\n",
    "class Log_regression:\n",
    "    def __init__(self,x_train,x_test,y_train,y_test):\n",
    "        self.x_train= x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "    def best_solver(self):\n",
    "        '''Gives the solver with best score or time '''\n",
    "        class_type = len(np.unique(y_train))\n",
    "        test_score = {}\n",
    "        train_score = {}\n",
    "        try:\n",
    "            if class_type > 2:\n",
    "                lg.info(\"Multiclass Classification requested\")\n",
    "                solvers = ['lbfgs', 'sag', 'saga', 'newton-cg'] #supported solver for Multiclass\n",
    "                try:\n",
    "                    for solver in solvers:\n",
    "                        model = LogisticRegression(solver=solver)\n",
    "                        model.fit(self.x_train,self.y_train)\n",
    "                        training_score = model.score(self.x_train,self.y_train)\n",
    "                        testing_score = model.score(self.x_test,self.y_test)\n",
    "                        test_score[solver] = testing_score\n",
    "                        train_score[solver] = training_score\n",
    "                except Exception as e:\n",
    "                    lg.error(e,\"Error occured while testing solvers\")\n",
    "\n",
    "\n",
    "            elif class_type ==2 :\n",
    "                lg.info(\"Binary Classification requested\")\n",
    "                solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'] #supported solver for binary class\n",
    "                try:\n",
    "                    for solver in solvers:\n",
    "                        model = LogisticRegression(solver=solver)\n",
    "                        model.fit(self.x_train,self.y_train)\n",
    "                        training_score = model.score(self.x_train,self.y_train)\n",
    "                        testing_score = model.score(self.x_test,self.y_test)\n",
    "                        test_score[solver] = testing_score\n",
    "                        train_score[solver] = training_score\n",
    "                        confusion_matrix()\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    lg.error(e,\"Error occured while testing solvers\")\n",
    "        except Exception as e:\n",
    "            lg.error(e,\"Problem in label data, no classes found\")\n",
    "        return test_score,train_score\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_preprocessing:\n",
    "    def __init__(self,dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def preprocess(self,label_col = ''):\n",
    "        '''Deletes NAN data, splits label and feature, label encoding, normalizing feature, train test split'''\n",
    "        try:\n",
    "            self.df.dropna(inplace=True)\n",
    "            x , y = self.df.drop([label_col],axis='columns'), self.df[label_col]\n",
    "            encode  = LabelEncoder()\n",
    "            y_encoded = encode.fit_transform(y)\n",
    "            scaler = StandardScaler()\n",
    "            x_scaled = scaler.fit_transform(x)\n",
    "            x_train,x_test,y_train,y_test = train_test_split(x_scaled,y_encoded,test_size=0.25,random_state=42)\n",
    "            return x_train,x_test,y_train,y_test\n",
    "        except Exception as e:\n",
    "            lg.error(e,\"Error occured while preprocessing\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "objct = data_preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = objct.preprocess('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi = Log_regression(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score,train_score = logi.best_solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lbfgs': 0.6715686274509803,\n",
       " 'sag': 0.6715686274509803,\n",
       " 'saga': 0.6715686274509803,\n",
       " 'newton-cg': 0.6715686274509803}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lbfgs': 0.6712964475963267,\n",
       " 'sag': 0.6713291284028889,\n",
       " 'saga': 0.6713291284028889,\n",
       " 'newton-cg': 0.6713291284028889}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e449e2464aa6784a7c762a4a40d023d951a287ecae2dad782490be59e801086b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
